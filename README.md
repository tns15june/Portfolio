
# Tarkeshwar Narayan Sharma
NLP | Deep Learning | Machine Learning | Artificial intelligence | Large Language Model | Prompt Engineering | Python | Big Data | SQL | Tableau | Excel

# Professional summary
* Data Scientist with over 6 years of cross-industry experience in developing end-to-end data science solutions and providing actionable business insights.
* Proficient in building statistical and predictive models using Python in Retail, E-commerce, Healthcare and Finance industries. Fortes include Machine-learning, Statistics, Deep Learning and Natural Language Processing

# Project 1: Aspect Based Sentiment Analysis

* The project aims to conduct aspect-based sentiment analysis on news articles and customer feedback in order to gain a deeper understanding of public sentiment towards specific topics or products. The project involves extracting key aspects or entities from the text data, such as specific products or companies, and then analyzing the sentiment expressed towards those aspects. The goal is to identify patterns and trends in sentiment across different news sources and customer feedback, and to use this information to inform business decisions or improve products and services. The project will involve using natural language processing techniques, such as named entity recognition and sentiment analysis, to analyze the text data. The results will be presented in the form of visualizations and reports, highlighting key findings and trends in sentiment towards specific aspects or entities.

# Project 2: News Summarization

* News summarization using the BART algorithm involves using a pre-trained transformer-based neural network to generate a condensed version of a news article. The algorithm works by encoding the input text and then using a decoder to generate a summary of the article.The first step in this process is to acquire a pre-trained BART model. This model can be downloaded from various sources such as the Hugging Face library. Once the model is downloaded, it can be loaded into the Python environment and fine-tuned for the specific task of news summarization.Next, the news article to be summarized is passed through the model. The input text is tokenized and encoded using the pre-trained BART model. The encoded text is then passed through the decoder, which generates a summary of the article.The generated summary can be further fine-tuned by adjusting the hyperparameters of the model. This can include adjusting the length of the summary, the number of attention heads, and the number of layers in the model.Finally, the generated summary can be evaluated for accuracy and fluency. This can be done by comparing the generated summary to a human-written summary of the same article.Overall, the BART algorithm is a powerful tool for news summarization as it can generate accurate and fluent summaries with minimal fine-tuning. It can be integrated into news applications to provide a quick and concise summary of the news article to the users.
